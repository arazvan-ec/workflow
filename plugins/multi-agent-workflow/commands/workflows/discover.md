---
name: workflows:discover
description: "Deep project analysis to build comprehensive knowledge. Scans codebase, detects patterns, and creates project profile."
argument_hint: [--full | --refresh | --report | --setup]
---

# /workflows:discover - Descubrimiento Profundo del Proyecto

**Version**: 1.0.0
**Category**: Setup & Analysis
**Priority**: Run once after installation, then periodically

---

## Purpose

Analiza el proyecto en profundidad para construir un conocimiento completo que permita al plugin trabajar de manera mÃ¡s efectiva. Genera un perfil del proyecto con toda la informaciÃ³n relevante.

## When to Use

| SituaciÃ³n | RecomendaciÃ³n |
|-----------|---------------|
| **First time using the plugin** | **`/workflows:discover --setup`** |
| Primera instalaciÃ³n del plugin | `/workflows:discover --full` |
| DespuÃ©s de cambios mayores (nueva librerÃ­a, refactor) | `/workflows:discover --refresh` |
| Ver resumen del conocimiento actual | `/workflows:discover --report` |
| Antes de planificar feature compleja | AutomÃ¡tico en `/workflows:plan` |
| Update specs after domain model changes | `/workflows:discover --specs-only` |
| Deep analysis of business rules | `/workflows:discover --specs-only --specs-depth=deep` |
| Generate API documentation baseline | `/workflows:discover --specs-only` then review `api-contracts/` |

## Invocation

```bash
# AnÃ¡lisis completo (primera vez)
/workflows:discover --full

# Refrescar conocimiento existente
/workflows:discover --refresh

# Solo mostrar reporte del conocimiento actual
/workflows:discover --report

# Por defecto: anÃ¡lisis inteligente (detecta quÃ© necesita actualizar)
/workflows:discover

# First-time setup (interactive onboarding + discovery)
/workflows:discover --setup
/workflows:discover --setup --reset  # Force reconfiguration

# Spec extraction examples
/workflows:discover --specs-only           # Only extract specs, skip profile
/workflows:discover --no-extract-specs     # Full discovery without spec extraction
/workflows:discover --specs-depth=deep     # Deep spec extraction (includes invariants, lifecycle)
/workflows:discover --full --specs-only    # Force re-extract all specs from scratch
```

## Execution Protocol

### Step 1: Create Project Intelligence Directory

```bash
mkdir -p .ai/project/intelligence
mkdir -p openspec/specs/entities
mkdir -p openspec/specs/api-contracts
mkdir -p openspec/specs/business-rules
mkdir -p openspec/specs/architectural-constraints
mkdir -p openspec/specs/api-consumers
```

### Step 2: Detect Project Type and Stack

Scan for configuration files and detect:

```markdown
## DetecciÃ³n de Stack

Escaneando archivos de configuraciÃ³n...

### Backend Detection
| Archivo | Framework/Lenguaje |
|---------|-------------------|
| `package.json` â†’ Node.js, dependencias |
| `composer.json` â†’ PHP, Symfony/Laravel |
| `requirements.txt` / `pyproject.toml` â†’ Python |
| `go.mod` â†’ Go |
| `Cargo.toml` â†’ Rust |
| `pom.xml` / `build.gradle` â†’ Java |
| `.csproj` â†’ .NET |

### Frontend Detection
| Archivo | Framework |
|---------|-----------|
| `package.json` â†’ React/Vue/Angular/Svelte |
| `tsconfig.json` â†’ TypeScript |
| `vite.config.*` â†’ Vite |
| `next.config.*` â†’ Next.js |
| `nuxt.config.*` â†’ Nuxt |

### Infrastructure Detection
| Archivo | TecnologÃ­a |
|---------|------------|
| `docker-compose.yml` â†’ Docker |
| `Dockerfile` â†’ Containerization |
| `.github/workflows/` â†’ GitHub Actions |
| `terraform/` â†’ Infrastructure as Code |
| `k8s/` / `kubernetes/` â†’ Kubernetes |
```

### Step 3: Analyze Project Structure

```markdown
## AnÃ¡lisis de Estructura

### Directory Map
```
[Generar Ã¡rbol de directorios hasta 3 niveles]
```

### Architecture Pattern Detection

| PatrÃ³n | Indicadores | Detectado |
|--------|-------------|-----------|
| **DDD (Domain-Driven Design)** | `domain/`, `application/`, `infrastructure/` | âœ“/âœ— |
| **Clean Architecture** | `entities/`, `usecases/`, `adapters/` | âœ“/âœ— |
| **MVC** | `models/`, `views/`, `controllers/` | âœ“/âœ— |
| **Hexagonal** | `ports/`, `adapters/` | âœ“/âœ— |
| **Atomic Design** | `atoms/`, `molecules/`, `organisms/` | âœ“/âœ— |
| **Feature-based** | Feature folders with all concerns | âœ“/âœ— |

### Layer Analysis (if DDD/Clean detected)
- Domain Layer: [path and health]
- Application Layer: [path and health]
- Infrastructure Layer: [path and health]
- Presentation Layer: [path and health]
```

### Step 4: Generate Architecture Profile

> **Agent**: `codebase-analyzer` | **Mode**: Architecture Profiling

Consolidate the stack, architecture, patterns, and conventions detected in Steps 2-3 into a structured architecture profile. Much of this information has already been gathered; this step formats and persists it.

#### What to Detect and Record

| Section | Fields |
|---------|--------|
| **Stack** | `language`, `framework`, `paradigm`, `type_system` |
| **Architecture** | `pattern` (hexagonal, mvc, layered, clean, etc.), `layers` with paths and dependencies, `separation_enforced` |
| **Patterns Detected** | `data_access`, `dependency_management`, `error_handling`, `async_pattern`, `testing_approach`, `http_client_pattern`, `external_api_integration`, `serialization_strategy`, `multi_platform_output`, `data_aggregation_pattern` |
| **External APIs** | `external_apis_consumed` (name, sdk, adapter, port, acl_compliant per consumed API) |
| **SOLID Relevance** | For each principle (SRP, OCP, LSP, ISP, DIP): `relevance` (high/medium/low), `metric`, `when_violated`, `reference_good` |
| **Conventions** | `naming` (classes, methods, files), `structure` (project-specific paths), `reference_files` (example files per archetype) |
| **Quality Thresholds** | `max_class_loc`, `max_public_methods`, `max_constructor_deps`, `max_interface_methods`, `max_files_per_simple_change` |

#### Output

Write the architecture profile to `openspec/specs/architecture-profile.yaml` using the template from `core/templates/architecture-profile-template.yaml`.

```bash
# Ensure the target directory exists
mkdir -p openspec/specs
```

```yaml
# openspec/specs/architecture-profile.yaml
# Generated by /workflows:discover on [DATE]
# Template: core/templates/architecture-profile-template.yaml

stack:
  language: "[detected from Step 2]"
  framework: "[detected from Step 2]"
  paradigm: "[oop|functional|mixed - inferred from codebase]"
  type_system: "[strong-static|strong-dynamic|weak-dynamic]"

architecture:
  pattern: "[detected from Step 3]"
  layers: [...]   # From Step 3 Layer Analysis
  separation_enforced: true|false

patterns_detected:
  data_access: "[repository|active-record|query-builder|...]"
  dependency_management: "[constructor-injection|container-autowire|...]"
  error_handling: "[exceptions|result-types|error-codes|mixed]"
  async_pattern: "[promises|async-await|callbacks|...]"
  testing_approach: "[tdd|test-after|minimal|none]"

solid_relevance:
  srp:
    relevance: "[high|medium|low]"
    metric: "[e.g., classes â‰¤200 LOC, â‰¤7 public methods]"
    when_violated: "[e.g., Extract Class, then compose]"
    reference_good: "[path to good SRP example in project]"
  ocp:
    relevance: "[high|medium|low]"
    metric: "[e.g., no switch/if-else chains by type]"
    when_violated: "[e.g., Strategy pattern]"
    reference_good: "[path]"
  lsp:
    relevance: "[high|medium|low]"
    metric: "[e.g., overrides respect parent contract]"
    when_violated: "[e.g., Composition over Inheritance]"
  isp:
    relevance: "[high|medium|low]"
    metric: "[e.g., interfaces â‰¤5 methods]"
    when_violated: "[action]"
    reference_good: "[path]"
  dip:
    relevance: "[high|medium|low]"
    metric: "[e.g., Domain/ imports zero from Infrastructure/]"
    when_violated: "[e.g., Port interface in Domain, Adapter in Infrastructure]"
    reference_good: "[path]"

conventions:
  naming:
    classes: "[PascalCase|camelCase|snake_case]"
    methods: "[camelCase|snake_case]"
    files: "[match-class-name|kebab-case|snake_case]"
  structure: {}    # Project-specific paths
  reference_files: {}   # Example files per archetype

quality_thresholds:
  max_class_loc: 200
  max_public_methods: 7
  max_constructor_deps: 7
  max_interface_methods: 5
  max_files_per_simple_change: 5
```

> **Note**: This profile is later enriched by `/workflows:compound` (Step 3c) with `learned_patterns` and `learned_antipatterns` as the project evolves.

### Step 5: Entity Specification Extraction

> **Agent**: `codebase-analyzer` | **Mode**: Entity Analysis

Extract domain entities and their specifications from the codebase:

```markdown
## Entity Specification Extraction

Scanning for domain entities and models...

### Detected Entities
| Entity | Location | Type | Attributes | Relations |
|--------|----------|------|------------|-----------|
| [EntityName] | `src/domain/entities/` | Aggregate/Entity/VO | X attrs | X relations |

### Entity Specification Format
For each entity, generate `openspec/specs/entities/[entity-name].yaml`:

```yaml
entity:
  name: "[EntityName]"
  type: "[aggregate|entity|value-object]"
  description: "[Purpose and business meaning]"

  attributes:
    - name: "[attr_name]"
      type: "[type]"
      required: true|false
      validation: "[rules]"
      description: "[meaning]"

  relations:
    - target: "[RelatedEntity]"
      type: "[one-to-one|one-to-many|many-to-many]"
      cardinality: "[0..1|1|0..*|1..*]"
      description: "[relationship meaning]"

  invariants:
    - "[Business rule that must always hold]"

  lifecycle:
    states: ["created", "active", "archived"]
    transitions:
      - from: "created"
        to: "active"
        trigger: "[event/action]"

  source_files:
    - "[path/to/entity.ts]"

  extracted_at: "[timestamp]"
```

### Extraction Depth
- **Surface**: Class/interface names and basic types
- **Standard**: Attributes, relations, basic validations
- **Deep**: Invariants, lifecycle, business rules embedded in code
```

### Step 6: API Contract Extraction

> **Agent**: `codebase-analyzer` | **Mode**: API Analysis

Extract API contracts and endpoint specifications:

```markdown
## API Contract Extraction

Scanning for API definitions...

### Sources Analyzed
| Source | Type | Endpoints Found |
|--------|------|-----------------|
| `routes/` | Express/Fastify routes | X |
| `controllers/` | Controller methods | X |
| `openapi.yaml` | OpenAPI spec | X |
| `*.graphql` | GraphQL schemas | X |

### Contract Specification Format
For each API group, generate `openspec/specs/api-contracts/[api-name].yaml`:

```yaml
api_contract:
  name: "[API Group Name]"
  version: "[detected version]"
  base_path: "/api/v1/[resource]"
  description: "[Purpose]"

  endpoints:
    - method: "GET|POST|PUT|PATCH|DELETE"
      path: "/[path]"
      description: "[what it does]"

      parameters:
        - name: "[param]"
          in: "path|query|header|body"
          type: "[type]"
          required: true|false
          validation: "[rules]"

      request:
        content_type: "application/json"
        schema:
          $ref: "#/schemas/[RequestDTO]"

      responses:
        - status: 200
          description: "Success"
          schema:
            $ref: "#/schemas/[ResponseDTO]"
        - status: 400
          description: "Validation error"
        - status: 401
          description: "Unauthorized"

      authentication: "[jwt|api-key|none]"
      rate_limit: "[if detected]"

  schemas:
    [SchemaName]:
      type: object
      properties:
        [field]: { type: "[type]" }

  source_files:
    - "[path/to/controller.ts]"
    - "[path/to/routes.ts]"

  extracted_at: "[timestamp]"
```

### Detection Methods
- Route decorator parsing (@Get, @Post, etc.)
- OpenAPI/Swagger file parsing
- GraphQL schema introspection
- Express/Fastify route analysis
- Controller method signature analysis
```

### Step 6b: External API Consumer Detection

> **Agent**: `codebase-analyzer` | **Mode**: API Consumer Analysis

Detect external APIs that the project CONSUMES (outgoing HTTP calls), as opposed to APIs it EXPOSES (incoming HTTP endpoints covered in Step 6).

```markdown
## External API Consumer Detection

Scanning for outgoing HTTP client usage and vendor SDK integrations...

### HTTP Client Detection
| Vendor/Library | Detected | Location | Usage Count |
|---------------|----------|----------|-------------|
| Symfony HttpClient | âœ“/âœ— | [files] | X calls |
| GuzzleHttp | âœ“/âœ— | [files] | X calls |
| curl (direct) | âœ“/âœ— | [files] | X calls |
| axios | âœ“/âœ— | [files] | X calls |
| fetch API | âœ“/âœ— | [files] | X calls |
| net/http (Go) | âœ“/âœ— | [files] | X calls |
| requests (Python) | âœ“/âœ— | [files] | X calls |

### Integration Pattern Analysis
| External API | SDK Used | Adapter Exists | Port/Interface Exists | ACL Compliant |
|-------------|----------|----------------|----------------------|---------------|
| [API Name] | [SDK] | âœ“/âœ— [path] | âœ“/âœ— [path] | âœ“/âœ— |

### Vendor SDK Isolation Check
| Layer | Vendor SDK Imports Found | Violation |
|-------|-------------------------|-----------|
| Domain/ | [list or "None"] | âœ“/âœ— |
| Application/ | [list or "None"] | âœ“/âœ— |
| Infrastructure/ | [list â€” expected here] | N/A |

### Async HTTP Pattern Detection
| Pattern | Detected | Location | Description |
|---------|----------|----------|-------------|
| Sequential calls | âœ“/âœ— | [files] | Multiple `->request()` in sequence |
| Promise/async batching | âœ“/âœ— | [files] | `Pool`, `Promise::all`, `stream()` |
| No concurrent calls | âœ“/âœ— | â€” | Single HTTP calls only |

### Serialization Pattern Detection
| Pattern | Detected | Location |
|---------|----------|----------|
| Symfony Serializer with @Groups | âœ“/âœ— | [files] |
| JMS Serializer | âœ“/âœ— | [files] |
| Manual toArray()/toJson() | âœ“/âœ— | [files] |
| Platform-specific DTOs | âœ“/âœ— | [files] |
| Transformer/Normalizer classes | âœ“/âœ— | [files] |

### Multi-Platform Output Detection
| Consumer | Response Format | Detected Via |
|----------|----------------|--------------|
| [Mobile app] | [Custom JSON] | [annotation/route/header] |
| [Web app] | [Full JSON] | [annotation/route/header] |
| [Single format] | [Standard] | [no platform differentiation] |
```

#### Detection Commands (stack-adapted)

```bash
# === HTTP Client Detection ===

# PHP
grep -rl "HttpClientInterface\|HttpClient::\|GuzzleHttp\|Client()" src/ 2>/dev/null | head -20
composer show 2>/dev/null | grep -i "http\|guzzle\|client"

# TypeScript/JavaScript
grep -rl "axios\|fetch(\|got(\|node-fetch\|superagent\|undici" src/ app/ lib/ 2>/dev/null | head -20

# Go
grep -rl "http.NewRequest\|http.Get\|http.Post\|http.Client" . --include="*.go" 2>/dev/null | head -20

# Python
grep -rl "requests.get\|requests.post\|httpx\|aiohttp\|urllib" . --include="*.py" 2>/dev/null | head -20

# === Adapter/Port Detection ===
find . -path "*/External/*" -name "*.php" -o -path "*/External/*" -name "*.ts" -o -path "*/External/*" -name "*.go" 2>/dev/null | head -20
grep -rl "ProviderInterface\|ClientInterface\|Gateway\|ApiAdapter" src/ 2>/dev/null | head -20

# === Serialization Detection ===
# PHP (Symfony)
grep -rl "@Groups\|@SerializedName\|NormalizerInterface\|SerializerInterface" src/ 2>/dev/null | head -20
grep -rl "JMS\\Serializer\|@Serializer\\" src/ 2>/dev/null | head -20

# TypeScript
grep -rl "class-transformer\|@Expose\|@Exclude\|plainToInstance" src/ 2>/dev/null | head -20

# === Multi-Platform Detection ===
grep -rl "platform\|X-Platform\|mobile\|web.*json\|app.*json" src/ 2>/dev/null | head -10
find . -name "*Mobile*DTO*" -o -name "*Web*DTO*" -o -name "*Mobile*Response*" -o -name "*Web*Response*" 2>/dev/null | head -10

# === Async HTTP Detection ===
# PHP
grep -rl "stream(\|Promise\|Pool::\|async\|concurrent\|amphp" src/ 2>/dev/null | head -10
# JS/TS
grep -rl "Promise.all\|Promise.allSettled\|Promise.race" src/ 2>/dev/null | head -10
# Go
grep -rl "sync.WaitGroup\|errgroup\|go func" . --include="*.go" 2>/dev/null | head -10
# Python
grep -rl "asyncio.gather\|concurrent.futures\|ThreadPoolExecutor" . --include="*.py" 2>/dev/null | head -10
```

#### Output Enrichment

Step 6b results are recorded in:
1. `openspec/specs/architecture-profile.yaml` under the new fields: `http_client_pattern`, `external_api_integration`, `serialization_strategy`, `multi_platform_output`, `data_aggregation_pattern`, and `external_apis_consumed`
2. A new spec file `openspec/specs/api-consumers/[api-name].yaml` for each detected external API

#### API Consumer Spec Format

For each detected external API, generate `openspec/specs/api-consumers/[api-name].yaml`:

```yaml
api_consumer:
  name: "[External API Name]"
  description: "[What this external API provides]"
  sdk: "[vendor/package-name]"

  integration:
    adapter: "[path/to/adapter]"
    port_interface: "[path/to/interface]"   # empty if missing (DIP violation)
    response_mapper: "[path/to/mapper]"     # empty if missing
    acl_compliant: true|false

  calls:
    - method: "GET|POST|PUT|DELETE"
      url_pattern: "[base_url/endpoint]"
      purpose: "[what this call retrieves/sends]"
      used_by: "[path/to/consuming/service]"

  async_grouping:
    grouped: true|false
    mechanism: "[Promise.all|Pool|stream|sequential]"

  response_mapping:
    vendor_types_leaked: true|false
    domain_dto: "[path/to/domain/dto]"

  source_files:
    - "[path/to/files]"

  extracted_at: "[timestamp]"
```

### Step 6c: Generate API Architecture Diagnostic

> **Agent**: `codebase-analyzer` | **Mode**: Dimensional Classification
> **Template**: `core/templates/api-architecture-diagnostic.yaml`

This step does NOT detect anything new â€” it classifies the results already detected in Steps 2-6b into dimensional values, then generates architectural constraints from first principles.

```markdown
## API Architecture Diagnostic

Classifying detected evidence into architectural dimensions...

### Dimensional Classification

Using results from Steps 2-6b, classify each dimension:

| Dimension | Value | Evidence Source |
|-----------|-------|----------------|
| **Data Flow** | [classified] | Step 2-3 (controllers = egress), Step 6b (HTTP clients = ingress) |
| **Data Source Topology** | [classified] | Step 6b (external API count + DB detection from Step 2) |
| **Consumer Diversity** | [classified] | Step 6b (serialization/multi-platform detection) |
| **Dependency Isolation** | [classified] | Step 6b (port + adapter + mapper per external API) |
| **Concurrency Model** | [classified] | Step 6b (async HTTP pattern detection) |
| **Response Customization** | [classified] | Step 6b (serialization pattern + platform-specific DTOs) |
```

#### Classification Rules

```
DIMENSION CLASSIFICATION (from Steps 2-6b evidence):

data_flow.primary:
  - HTTP client libs detected AND controllers detected â†’ "bidirectional"
  - HTTP client libs detected, minimal controllers â†’ "ingress"
  - Controllers detected, no HTTP clients â†’ "egress"
  - 3+ external sources combined into single response â†’ "aggregation"
  - Proxy routes, gateway patterns, minimal logic â†’ "passthrough"
  - Mapper/transformer classes as primary pattern â†’ "transformation"

data_source_topology.value:
  - No external APIs, one DB detected â†’ "single_db"
  - No external APIs, multiple DBs â†’ "multi_db"
  - 1 external API, no DB â†’ "single_external"
  - 2+ external APIs, no DB â†’ "multi_external"
  - External APIs + DB(s) â†’ "mixed_db_external"
  - Message queues/event streams as primary â†’ "event_driven"
  - Mix of DBs, APIs, and events â†’ "hybrid"

consumer_diversity.value:
  - No platform differentiation detected â†’ "single_consumer"
  - Platform-specific DTOs/serialization groups â†’ "multi_platform"
  - Service-to-service contracts detected â†’ "inter_service"
  - Public API docs/versioning detected â†’ "public_api"
  - Combination of above â†’ "mixed"

dependency_isolation.value:
  - No external APIs â†’ "no_externals"
  - All externals have port + adapter + mapper â†’ "fully_isolated"
  - Some adapters exist but ports/mappers missing â†’ "partially_wrapped"
  - External SDKs used directly in Application/Domain â†’ "direct_coupling"

concurrency_model.value:
  - No async patterns, sequential calls only â†’ "synchronous"
  - Framework supports async but not used â†’ "async_capable"
  - Async/concurrent patterns actively used â†’ "fully_concurrent"
  - Single external call or no external calls â†’ "not_applicable"

response_customization.value:
  - Same response for all consumers â†’ "uniform"
  - Field filtering (e.g., ?fields=id,name) â†’ "parameterized"
  - Different DTOs/transformers per consumer â†’ "per_consumer_shaped"
  - Response varies by auth/role/feature flags â†’ "context_dependent"
```

#### Constraint Generation

Apply the IF-THEN rules documented in `core/templates/api-architecture-diagnostic.yaml` for each dimension:

1. **Per-dimension constraints**: For each classified dimension, apply its constraint rules
2. **Derived constraints**: Check dimension combinations that produce compound risks:
   - `multi_external` + `direct_coupling` â†’ CRITICAL vendor risk
   - `aggregation` + `synchronous` â†’ WARNING latency proportional to source count
   - `multi_platform` + `per_consumer_shaped` â†’ Platform-specific transformers required
   - `aggregation` + `multi_external` â†’ Assembler pattern with independent Providers
   - `multi_external` + `synchronous` â†’ Performance bottleneck
3. **Constraint summary**: Aggregate into `must`, `should`, and `review_criteria` lists
4. **Pattern mapping**: Map each active constraint to corrective patterns (AC-01 through AC-04) in `architecture-reference.md`

#### Output

Write the diagnostic to `openspec/specs/api-architecture-diagnostic.yaml` using the template:

```bash
# Copy template and populate with classified values
cp plugins/multi-agent-workflow/core/templates/api-architecture-diagnostic.yaml openspec/specs/api-architecture-diagnostic.yaml

# Fill in:
# - diagnostic_version, generated_at, generated_by
# - Each dimension's value, evidence[], and constraints[]
# - derived_constraints[]
# - constraint_summary.must[], .should[], .review_criteria[]
# - pattern_mapping[]
# - extracted_from[], extraction_method, last_validated
```

> **Skip condition**: If Step 6b found no external APIs AND no multi-platform output AND no multi-source aggregation, skip this step (the project has no API architecture complexity to diagnose).

### Step 7: Business Rule Extraction

> **Agent**: `codebase-analyzer` | **Mode**: Business Rule Analysis

Extract business rules and domain logic:

```markdown
## Business Rule Extraction

Analyzing domain logic for business rules...

### Rule Sources
| Source | Location | Rules Found |
|--------|----------|-------------|
| Domain Services | `src/domain/services/` | X |
| Entity Methods | `src/domain/entities/` | X |
| Validators | `src/domain/validators/` | X |
| Specifications | `src/domain/specifications/` | X |
| Policy Classes | `src/domain/policies/` | X |

### Business Rule Specification Format
Generate `openspec/specs/business-rules/[domain-area].yaml`:

```yaml
business_rules:
  domain_area: "[Area Name]"
  description: "[What this area covers]"

  rules:
    - id: "BR-[AREA]-001"
      name: "[Human-readable name]"
      description: "[What the rule enforces]"

      type: "[validation|calculation|authorization|workflow|constraint]"

      condition:
        when: "[trigger condition]"
        given: "[preconditions]"
        then: "[expected outcome]"

      implementation:
        location: "[file path]"
        method: "[method name]"
        pattern: "[specification|policy|validator|guard]"

      exceptions:
        - "[when rule doesn't apply]"

      related_entities:
        - "[Entity1]"
        - "[Entity2]"

      test_coverage:
        unit_tests: "[path to tests]"
        scenarios_tested: X

      priority: "[critical|high|medium|low]"

  cross_cutting_rules:
    - id: "BR-CROSS-001"
      name: "[Rule spanning multiple areas]"
      affected_areas: ["Area1", "Area2"]
      description: "[rule description]"

  source_files:
    - "[path/to/service.ts]"

  extracted_at: "[timestamp]"
```

### Rule Detection Heuristics
- Guard clauses and validation logic
- if/throw patterns with business messages
- Specification pattern implementations
- Policy class decisions
- Domain event triggers
```

### Step 8: Architectural Constraint Extraction

> **Agent**: `codebase-analyzer` | **Mode**: Constraint Analysis

Extract architectural constraints and design decisions:

```markdown
## Architectural Constraint Extraction

Analyzing codebase for architectural constraints...

### Constraint Categories
| Category | Source | Constraints Found |
|----------|--------|-------------------|
| Layer Dependencies | Import analysis | X |
| Module Boundaries | Package structure | X |
| Design Patterns | Code patterns | X |
| Security Constraints | Auth/Authz code | X |
| Performance Constraints | Caching/optimization | X |

### Constraint Specification Format
Generate `openspec/specs/architectural-constraints/[category].yaml`:

```yaml
architectural_constraints:
  category: "[Category Name]"
  description: "[What these constraints govern]"

  layer_constraints:
    - name: "Domain Layer Purity"
      description: "Domain layer has no external dependencies"
      rule: "src/domain/** cannot import from src/infrastructure/**"
      enforcement: "[eslint-rule|architect-review|ci-check]"
      violations_found: X

    - name: "Dependency Direction"
      description: "Dependencies point inward"
      layers:
        - { name: "presentation", can_depend_on: ["application"] }
        - { name: "application", can_depend_on: ["domain"] }
        - { name: "domain", can_depend_on: [] }

  module_constraints:
    - name: "[Module Boundary]"
      description: "[What the boundary enforces]"
      modules:
        - name: "[ModuleName]"
          public_api: "[exposed interface]"
          internal: "[hidden implementation]"
          dependencies: ["[allowed modules]"]

  pattern_constraints:
    - name: "Repository Pattern"
      description: "All data access through repositories"
      applies_to: "src/domain/**"
      pattern: "Repository"
      anti_patterns: ["Direct DB calls in domain"]

    - name: "[Pattern Name]"
      applies_to: "[scope]"
      required: true|false

  security_constraints:
    - name: "[Security Constraint]"
      description: "[What it protects]"
      enforcement: "[how enforced]"
      scope: "[affected areas]"

  performance_constraints:
    - name: "[Performance Constraint]"
      description: "[What it optimizes]"
      threshold: "[metric]"
      implementation: "[how achieved]"

  technology_constraints:
    - name: "[Tech Constraint]"
      description: "[Why this constraint exists]"
      allowed: ["[tech1]", "[tech2]"]
      forbidden: ["[tech3]"]
      reason: "[rationale]"

  source_evidence:
    - "[path/to/architectural/decision]"

  extracted_at: "[timestamp]"
```

### Detection Methods
- Import/dependency graph analysis
- Package.json/tsconfig path mappings
- ESLint/architecture rules
- ADR (Architecture Decision Records) parsing
- Code pattern recognition
```

### Step 9: Generate Spec Manifest

Create `openspec/specs/spec-manifest.yaml` to index all extracted specs:

```yaml
# Auto-generated spec manifest
# Updated by /workflows:discover on [DATE]

manifest:
  version: "1.0"
  generated_at: "[timestamp]"
  project: "[project-name]"

  statistics:
    entities: X
    api_contracts: X
    business_rules: X
    architectural_constraints: X
    api_consumers: X
    total_specs: X

  entities:
    - name: "[Entity1]"
      file: "entities/entity1.yaml"
      type: "aggregate"
      last_updated: "[timestamp]"

  api_contracts:
    - name: "[API1]"
      file: "api-contracts/api1.yaml"
      endpoints: X
      last_updated: "[timestamp]"

  business_rules:
    - domain_area: "[Area1]"
      file: "business-rules/area1.yaml"
      rules_count: X
      critical_rules: X
      last_updated: "[timestamp]"

  architectural_constraints:
    - category: "[Category1]"
      file: "architectural-constraints/category1.yaml"
      constraints_count: X
      last_updated: "[timestamp]"

  api_consumers:
    - name: "[ExternalAPI1]"
      file: "api-consumers/external-api1.yaml"
      acl_compliant: true|false
      last_updated: "[timestamp]"

  api_architecture_diagnostic:
    file: "api-architecture-diagnostic.yaml"
    dimensions_classified: X
    constraints_must: X
    constraints_should: X
    last_updated: "[timestamp]"

  extraction_config:
    extract_specs: true
    depth: "standard"
    include_tests: false

  next_recommended_update: "[timestamp + 7 days]"
```

### Step 10: Scan Code Patterns (Skip if --specs-only)

```markdown
## Patrones de CÃ³digo Detectados

### Naming Conventions
| Tipo | PatrÃ³n Detectado | Ejemplo |
|------|------------------|---------|
| Archivos | kebab-case / PascalCase / camelCase | `user-service.ts` |
| Clases | PascalCase | `UserService` |
| Funciones | camelCase | `getUserById` |
| Variables | camelCase | `userId` |
| Constantes | UPPER_SNAKE | `MAX_RETRIES` |
| Interfaces | I-prefix / no-prefix | `IUserRepository` |

### Code Style
- Indentation: [tabs/spaces, size]
- Quotes: [single/double]
- Semicolons: [yes/no]
- Line length: [detected max]
- Import style: [absolute/relative]

### Testing Patterns
| Tipo | Framework | UbicaciÃ³n | Cobertura Estimada |
|------|-----------|-----------|-------------------|
| Unit | Jest/PHPUnit/pytest | `__tests__/`, `tests/` | X% |
| Integration | Supertest/etc | `tests/integration/` | X% |
| E2E | Playwright/Cypress | `e2e/`, `tests/e2e/` | X% |
```

### Step 11: Analyze Dependencies (Skip if --specs-only)

```markdown
## AnÃ¡lisis de Dependencias

### Core Dependencies
| Paquete | VersiÃ³n | PropÃ³sito |
|---------|---------|-----------|
| [framework] | vX.X | Core framework |
| [orm] | vX.X | Database |
| [auth] | vX.X | Authentication |

### Dev Dependencies Relevantes
| Paquete | PropÃ³sito |
|---------|-----------|
| [test-framework] | Testing |
| [linter] | Code quality |
| [formatter] | Formatting |

### Potential Security Concerns
[Ejecutar audit si disponible]

### Dependency Graph Highlights
- Total dependencies: X
- Direct: X
- Transitive: X
- Outdated: X
```

### Step 12: Git History Analysis (Skip if --specs-only)

```markdown
## AnÃ¡lisis de Historia Git

### Repository Stats
| MÃ©trica | Valor |
|---------|-------|
| Total commits | X |
| Contributors | X |
| First commit | YYYY-MM-DD |
| Last commit | YYYY-MM-DD |
| Active branches | X |

### Commit Patterns
| PatrÃ³n | Uso |
|--------|-----|
| Conventional Commits | âœ“/âœ— |
| Prefix style | feat:/fix:/etc |
| Typical commit size | X files, X lines |

### Hotspots (most changed files)
| Archivo | Cambios | Riesgo |
|---------|---------|--------|
| [file1] | X commits | Alto/Medio/Bajo |
| [file2] | X commits | Alto/Medio/Bajo |

### Recent Activity
[Ãšltimos 10 commits relevantes]
```

### Step 13: Detect Existing Documentation (Skip if --specs-only)

```markdown
## DocumentaciÃ³n Existente

| Archivo | Tipo | Estado |
|---------|------|--------|
| `README.md` | General | âœ“/âœ— |
| `CONTRIBUTING.md` | Contribution | âœ“/âœ— |
| `docs/` | Documentation folder | âœ“/âœ— |
| `API.md` | API docs | âœ“/âœ— |
| `CHANGELOG.md` | Change history | âœ“/âœ— |
| `.ai/` | AI context | âœ“/âœ— |

### Code Documentation
- JSDoc/TSDoc/PHPDoc coverage: X%
- README in key directories: X/Y
```

### Step 14: Generate Project Profile (Skip if --specs-only)

Create `.ai/project/intelligence/project-profile.md`:

```markdown
# Project Profile: [Project Name]

> Auto-generated by /workflows:discover on [DATE]
> Last updated: [TIMESTAMP]

---

## Quick Facts

| Attribute | Value |
|-----------|-------|
| **Type** | [Web App / API / Library / CLI / Monorepo] |
| **Primary Language** | [TypeScript / PHP / Python / etc] |
| **Framework** | [React + Node / Symfony / Django / etc] |
| **Architecture** | [DDD / MVC / Clean / Monolith / Microservices] |
| **Database** | [PostgreSQL / MySQL / MongoDB / etc] |
| **Complexity** | [Low / Medium / High / Very High] |
| **Test Coverage** | [X%] |
| **Team Size** | [Solo / Small / Medium / Large] (inferred from git) |

---

## Tech Stack

### Backend
- **Runtime**: [Node.js 20 / PHP 8.3 / Python 3.12]
- **Framework**: [Express / NestJS / Symfony / FastAPI]
- **ORM**: [Prisma / TypeORM / Doctrine / SQLAlchemy]
- **Auth**: [JWT / Session / OAuth]

### Frontend
- **Framework**: [React 18 / Vue 3 / Angular 17]
- **State**: [Redux / Zustand / Pinia]
- **Styling**: [Tailwind / CSS Modules / Styled Components]
- **Build**: [Vite / Webpack / Turbopack]

### Infrastructure
- **Container**: [Docker / Podman]
- **CI/CD**: [GitHub Actions / GitLab CI / Jenkins]
- **Cloud**: [AWS / GCP / Azure / Vercel]
- **Monitoring**: [DataDog / Sentry / etc]

---

## Architecture Overview

### Structure
```
[Simplified directory tree with annotations]
```

### Patterns in Use
- [Pattern 1]: Used in [location], purpose: [why]
- [Pattern 2]: Used in [location], purpose: [why]

### Key Abstractions
| Abstraction | Location | Purpose |
|-------------|----------|---------|
| Repository | `src/infrastructure/repositories/` | Data access |
| Service | `src/application/services/` | Business logic |
| Controller | `src/presentation/controllers/` | HTTP handling |

### Companion: Architecture Profile
> Detailed architecture analysis (stack, SOLID relevance, patterns, quality thresholds) is maintained in
> `openspec/specs/architecture-profile.yaml` (generated by Step 4). The project profile provides a
> human-readable overview; the architecture profile provides machine-readable detail for the solid-analyzer
> and other automated skills.

---

## Code Conventions

### Naming
```typescript
// Files: kebab-case
user-service.ts

// Classes: PascalCase
class UserService {}

// Functions: camelCase
function getUserById() {}

// Interfaces: PascalCase (no I-prefix)
interface UserRepository {}
```

### Style Rules
- Indent: 2 spaces
- Quotes: single
- Semicolons: no
- Max line: 100 chars
- Imports: absolute paths from `src/`

### Testing Convention
- Unit tests: `*.test.ts` next to source
- Integration: `tests/integration/`
- E2E: `e2e/`
- Coverage target: 80%

---

## Reference Implementations

When implementing new features, use these as templates:

### Entity Example
â†’ `src/domain/entities/User.ts`

### Repository Example
â†’ `src/infrastructure/repositories/UserRepository.ts`

### Service Example
â†’ `src/application/services/AuthService.ts`

### Controller Example
â†’ `src/presentation/controllers/UserController.ts`

### Component Example
â†’ `src/components/UserProfile/UserProfile.tsx`

### Test Example
â†’ `src/domain/entities/User.test.ts`

---

## Known Patterns & Anti-Patterns

### Patterns to Follow
1. **[Pattern Name]**: [Description and when to use]
2. **[Pattern Name]**: [Description and when to use]

### Anti-Patterns to Avoid
1. **[Anti-Pattern]**: [Why and what to do instead]
2. **[Anti-Pattern]**: [Why and what to do instead]

---

## Project Health

### Strengths
- âœ… [Strength 1]
- âœ… [Strength 2]

### Areas for Improvement
- âš ï¸ [Area 1]: [Recommendation]
- âš ï¸ [Area 2]: [Recommendation]

### Technical Debt
| Item | Severity | Location |
|------|----------|----------|
| [Debt item] | High/Med/Low | [File/area] |

---

## Workflow Recommendations

Based on this project's characteristics:

| Task Type | Recommended Workflow | Why |
|-----------|---------------------|-----|
| New Feature | `/workflows:plan` (full) | Complex architecture needs planning |
| Bug Fix | `/workflows:route` â†’ work | Direct fix with review |
| Refactor | `/workflows:plan` + `/workflows:work` | SOLID analysis in plan phase |
| Performance | Performance Review Agent | Specialized analysis |

### Trust Level by Area
| Area | Trust | Approach |
|------|-------|----------|
| Domain layer | High | Established patterns |
| New modules | Medium | Verify with reviewer |
| External integrations | Low | Extra review needed |

---

## Quick Commands for This Project

```bash
# Run tests
[detected test command]

# Start dev server
[detected dev command]

# Build
[detected build command]

# Lint
[detected lint command]

# Type check
[detected type check command]
```

---

*Profile regenerated automatically. Manual edits will be preserved in sections marked `<!-- CUSTOM -->`*
```

### Step 15: Generate Config if Missing (Skip if --specs-only)

If `.ai/project/config.yaml` doesn't exist, create it:

```yaml
# Auto-generated by /workflows:discover
# Manual edits are preserved on refresh

project:
  name: "[detected]"
  type: "[web-app|api|library|cli|monorepo]"
  description: "[from README or package.json]"

backend:
  framework: "[detected]"
  language: "[detected]"
  path: "[detected]"

frontend:
  framework: "[detected]"
  language: "[detected]"
  path: "[detected]"

database:
  type: "[detected]"
  orm: "[detected]"

architecture:
  pattern: "[ddd|mvc|clean|hexagonal|feature-based]"
  layers:
    - name: domain
      path: src/domain
    - name: application
      path: src/application
    - name: infrastructure
      path: src/infrastructure

testing:
  framework: "[detected]"
  coverage_target: 80
  locations:
    unit: "**/*.test.ts"
    integration: "tests/integration/"
    e2e: "e2e/"

conventions:
  commits: conventional
  branches: "[detected pattern]"
  file_naming: kebab-case

ai_analysis:
  last_scan: "[timestamp]"
  complexity: "[low|medium|high|very-high]"
  detected_patterns: []
  reference_files: {}

workflow:
  default: standard
  auto_refresh: true
  session_max_messages: 50
```

### Step 16: Display Summary

```markdown
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Discovery Completado                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## Resumen del Proyecto

| Aspecto | Detectado |
|---------|-----------|
| **Nombre** | [project-name] |
| **Tipo** | [type] |
| **Stack** | [backend] + [frontend] |
| **Arquitectura** | [pattern] |
| **Complejidad** | [level] |

## Archivos Generados

âœ… `.ai/project/intelligence/project-profile.md` - Perfil completo
âœ… `.ai/project/config.yaml` - ConfiguraciÃ³n del proyecto
âœ… `.ai/project/context.md` - Contexto para agentes
âœ… `openspec/specs/architecture-profile.yaml` - Architecture profile (stack, SOLID, patterns, thresholds)

### Spec Files (if --extract-specs enabled)

âœ… `openspec/specs/entities/*.yaml` - Entity specifications
âœ… `openspec/specs/api-contracts/*.yaml` - API contract definitions
âœ… `openspec/specs/business-rules/*.yaml` - Business rule documentation
âœ… `openspec/specs/architectural-constraints/*.yaml` - Architecture constraints
âœ… `openspec/specs/spec-manifest.yaml` - Spec index and metadata

## Conocimiento Capturado

- ğŸ“ Estructura: [X] directorios mapeados
- ğŸ”§ Patrones: [X] patrones detectados
- ğŸ“¦ Dependencias: [X] analizadas
- ğŸ“ Commits: [X] analizados
- ğŸ¯ Referencias: [X] archivos template identificados

## Specs Extracted (if --extract-specs enabled)

| Spec Type | Count | Files Generated |
|-----------|-------|-----------------|
| **Entities** | [X] | `openspec/specs/entities/` |
| **API Contracts** | [X] | `openspec/specs/api-contracts/` |
| **Business Rules** | [X] | `openspec/specs/business-rules/` |
| **Architectural Constraints** | [X] | `openspec/specs/architectural-constraints/` |
| **API Consumers** | [X] | `openspec/specs/api-consumers/` |
| **API Architecture Diagnostic** | [1 if generated] | `openspec/specs/api-architecture-diagnostic.yaml` |
| **Total Specs** | [X] | See `spec-manifest.yaml` |

> Specs extracted by `codebase-analyzer` agent. Run `/workflows:discover --specs-only` to update specs without full discovery.

## PrÃ³ximos Pasos

1. **Revisar el perfil**: `cat .ai/project/intelligence/project-profile.md`
2. **Ajustar si necesario**: Edita `config.yaml` para correcciones
3. **Empezar a trabajar**: `/workflows:plan tu-feature`

> El plugin ahora tiene conocimiento profundo de tu proyecto.
> Este conocimiento se usa automÃ¡ticamente en planning y reviews.
```

## Flags

| Flag | Description |
|------|-------------|
| `--full` | AnÃ¡lisis completo desde cero (sobrescribe) |
| `--refresh` | Actualiza solo lo que cambiÃ³ |
| `--report` | Solo muestra el perfil actual sin re-escanear |
| `--setup` | Interactive onboarding: auto-detect stack + configure plugin |
| `--reset` | Force reconfiguration (with --setup) |
| `--quiet` | Menos output, solo errores |
| `--extract-specs` | Enable spec extraction (default: true) |
| `--no-extract-specs` | Disable spec extraction |
| `--specs-only` | Only extract specs, skip profile generation |
| `--specs-depth=[surface\|standard\|deep]` | Depth of spec extraction (default: standard) |

## Integration with Other Commands

- **`/workflows:plan`**: Lee el project-profile para informar planificaciÃ³n
- **`/workflows:work`**: Usa convenciones detectadas para cÃ³digo consistente
- **`/workflows:review`**: Valida contra patrones documentados
- **`/workflows:compound`**: Actualiza perfil con nuevos aprendizajes

### Spec Extraction Agent

The `codebase-analyzer` agent is responsible for all specification extraction:

| Mode | Purpose | Output |
|------|---------|--------|
| Entity Analysis | Extract domain entities and models | `specs/entities/*.yaml` |
| API Analysis | Extract API contracts and endpoints | `specs/api-contracts/*.yaml` |
| Business Rule Analysis | Extract business rules and domain logic | `specs/business-rules/*.yaml` |
| Constraint Analysis | Extract architectural constraints | `specs/architectural-constraints/*.yaml` |

The agent uses static analysis, pattern recognition, and AST parsing to extract specifications from the codebase without requiring runtime execution.

## Auto-Discovery Triggers

El discovery se ejecuta automÃ¡ticamente cuando:
1. Se detecta que no existe `.ai/project/config.yaml`
2. Han pasado mÃ¡s de 7 dÃ­as desde el Ãºltimo scan
3. Se detectan cambios significativos en `package.json` o equivalente

---

## Setup Mode (`--setup`)

Interactive onboarding that auto-detects your project stack and configures the plugin. Replaces the former `/workflows:quickstart` command.

### When to Use

- **First time** using the plugin in a project
- After `--reset` to reconfigure from scratch
- When onboarding a new team member to an existing project

### Setup Protocol

#### Setup Step 0: Check if Already Configured

```
if .ai/project/ directory exists AND --reset flag NOT provided:
  OUTPUT: "This project is already configured."
  SHOW: Current configuration summary
  ASK: "Do you want to reconfigure? (use --reset to force)"
  EXIT
```

#### Setup Step 1: Auto-Detect Project Stack

Runs the standard discovery Steps 2-3 (detect stack + analyze structure), then presents:

```markdown
## Detected Stack

| Component       | Detected           | Source              |
|----------------|-------------------|---------------------|
| Backend        | [detected]         | [source file]       |
| Frontend       | [detected]         | [source file]       |
| Architecture   | [detected]         | [evidence]          |
| Database       | [detected]         | [source file]       |
| Testing        | [detected]         | [source file]       |
| Containerized  | Yes/No             | [source file]       |

> Correct? If not, I'll adjust. Otherwise, let's continue.
```

#### Setup Step 2: Ask Only What Cannot Be Detected (2-3 questions max)

**Question 1: Execution Mode**

```
How do you want to work with the AI agents?

  [1] Agent Executes (Recommended)
      â†’ AI writes code, runs tests, auto-corrects. You review at checkpoints.

  [2] Hybrid
      â†’ AI writes code but pauses before each checkpoint for your approval.

  [3] Human Guided
      â†’ AI plans and instructs. You write the code. AI verifies.
```

**Question 2: Review Intensity**

```
How strict should code reviews be?

  [1] Strict (Recommended for teams / production code)
      â†’ All review agents run. Full SOLID compliance verification required.

  [2] Balanced
      â†’ Core review agents (security, architecture, code). SOLID compliance verified.

  [3] Light (Good for prototypes / MVPs)
      â†’ Only security review + basic code quality. SOLID informational only.
```

**Question 3: Team Context** (only if not detectable)

```
Is this a solo project or a team project?

  [1] Solo developer
  [2] Small team (2-5)
  [3] Larger team (5+)
```

#### Setup Step 3: Generate Project Configuration

Based on detection + answers, generate the `.ai/` directory structure:

```bash
.ai/
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ specs/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”œâ”€â”€ api-contracts/
â”‚   â”‚   â”œâ”€â”€ business-rules/
â”‚   â”‚   â””â”€â”€ spec-manifest.yaml
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ compound_log.md
â”‚   â”œâ”€â”€ compound-memory.md
â”‚   â”œâ”€â”€ validation-learning-log.md
â”‚   â””â”€â”€ analysis/
â””â”€â”€ extensions/
```

Generate `providers-override.yaml` and initialize `compound-memory.md` and `validation-learning-log.md` with project profile and default calibration.

#### Setup Step 4: Show "The Flow" and Next Step

```markdown
## You're Ready!

Here's how the workflow works:

  ROUTE â†’ SHAPE â†’ PLAN â†’ WORK â†’ REVIEW â†’ COMPOUND

### Your Next Step

Run this command to start your first feature:

  /workflows:route <describe your feature>

### Quick Reference

| Command             | What it does                    |
|--------------------|--------------------------------|
| /workflows:route   | Classify and route your request |
| /workflows:plan    | Create implementation plan      |
| /workflows:work    | Execute the plan                |
| /workflows:review  | Quality review                  |
| /workflows:compound| Capture learnings               |
| /workflows:help    | Full reference                  |
```

---

## Related Commands

- `/workflows:status` - Estado actual
